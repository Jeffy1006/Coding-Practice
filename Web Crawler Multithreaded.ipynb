{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent import futures\n",
    "\n",
    "class Solution:\n",
    "    def crawl(self, startUrl: str, htmlParser: 'HtmlParser'):\n",
    "        hostname = lambda url: url.split('/')[2]\n",
    "        seen = {startUrl}\n",
    "    \n",
    "        with futures.ThreadPoolExecutor(max_workers=16) as executor:\n",
    "            tasks = deque([executor.submit(htmlParser.getUrls, startUrl)])\n",
    "            while tasks:\n",
    "                for url in tasks.popleft().result():\n",
    "                    if url not in seen and hostname(startUrl) == hostname(url):\n",
    "                        seen.add(url)\n",
    "                        tasks.append(executor.submit(htmlParser.getUrls, url))\n",
    "        \n",
    "        return list(seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "from queue import Queue\n",
    "\n",
    "class Solution:\n",
    "    def crawl(self, startUrl: str, htmlParser: 'HtmlParser'):\n",
    "        def hostname(url):\n",
    "            start = len(\"http://\")\n",
    "            i = start\n",
    "            while i < len(url) and url[i] != \"/\":\n",
    "                i += 1\n",
    "            return url[start:i]\n",
    "        \n",
    "        queue = Queue()\n",
    "        seen = {startUrl}\n",
    "        start_hostname = hostname(startUrl)\n",
    "        seen_lock = threading.Lock()\n",
    "        \n",
    "        def worker():\n",
    "            while True:\n",
    "                url = queue.get()\n",
    "                if url is None:\n",
    "                    return\n",
    "\n",
    "                for next_url in htmlParser.getUrls(url):\n",
    "                    if next_url not in seen and hostname(next_url) == start_hostname:\n",
    "                        seen_lock.acquire()\n",
    "                        # Acquire lock to ensure urls are no enqueed multiple times\n",
    "                        if next_url not in seen:\n",
    "                            seen.add(next_url)\n",
    "                            queue.put(next_url)\n",
    "                        seen_lock.release()\n",
    "                queue.task_done()\n",
    "        \n",
    "        num_workers = 8\n",
    "        workers = []\n",
    "        queue.put(startUrl)\n",
    "        \n",
    "        for i in range(num_workers):\n",
    "            t = threading.Thread(target=worker)\n",
    "            t.start()\n",
    "            workers.append(t)\n",
    "        \n",
    "        # Wait until empty\n",
    "        queue.join()\n",
    "        \n",
    "        for i in range(num_workers):\n",
    "            queue.put(None)\n",
    "        for t in workers:\n",
    "            t.join()\n",
    "        \n",
    "        return list(seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent import futures\n",
    "from queue import Queue\n",
    "\n",
    "import threading\n",
    "class Solution(object):\n",
    "    def crawl(self, startUrl, htmlParser):\n",
    "        common_host = startUrl.split('/')[2]\n",
    "        queue, seen, seen_lock = Queue(), {startUrl}, threading.Lock()\n",
    "        def worker():\n",
    "            try:\n",
    "                while True:\n",
    "                    url = queue.get(timeout=0.015) # make sure wait up to the time required for the `getUrls` call\n",
    "                    for next_url in htmlParser.getUrls(url):\n",
    "                        if next_url not in seen and next_url.split('/')[2] == common_host:\n",
    "                            seen_lock.acquire()\n",
    "                            # Acquire lock to ensure urls are no enqueed multiple times\n",
    "                            if next_url not in seen:\n",
    "                                seen.add(next_url)\n",
    "                                queue.put(next_url)\n",
    "                            seen_lock.release()\n",
    "                    queue.task_done()\n",
    "            except: pass\n",
    "        \n",
    "        queue.put(startUrl)\n",
    "        with futures.ThreadPoolExecutor(max_workers=8) as executor:\n",
    "            for i in range(8): executor.submit(worker)\n",
    "        \n",
    "        return list(seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
